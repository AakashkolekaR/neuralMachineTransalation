{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvn8-qe5Fxat",
        "outputId": "ea76fc94-b041-4380-e1c8-cea90f60c232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install awswrangler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCaWPZIcXN8p",
        "outputId": "b1072a2f-1fe1-44ae-9625-8c46043df0bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting awswrangler\n",
            "  Downloading awswrangler-2.15.1-py3-none-any.whl (239 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 30.9 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 20.7 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 143 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 174 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 184 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 204 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 215 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 235 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 239 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: openpyxl<3.1.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from awswrangler) (3.0.9)\n",
            "Collecting botocore<2.0.0,>=1.23.17\n",
            "  Downloading botocore-1.24.44-py3-none-any.whl (8.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 62.4 MB/s \n",
            "\u001b[?25hCollecting gremlinpython<4.0.0,>=3.5.2\n",
            "  Downloading gremlinpython-3.6.0-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas<2.0.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from awswrangler) (1.3.5)\n",
            "Collecting pymysql<2.0.0,>=1.0.0\n",
            "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting redshift-connector<2.1.0,>=2.0.889\n",
            "  Downloading redshift_connector-2.0.906-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 77.1 MB/s \n",
            "\u001b[?25hCollecting boto3<2.0.0,>=1.20.17\n",
            "  Downloading boto3-1.21.44-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 63.1 MB/s \n",
            "\u001b[?25hCollecting progressbar2<5.0.0,>=4.0.0\n",
            "  Downloading progressbar2-4.0.0-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: pyarrow<7.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from awswrangler) (6.0.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from awswrangler) (1.21.6)\n",
            "Collecting pg8000<2.0.0,>=1.20.0\n",
            "  Downloading pg8000-1.26.0-py3-none-any.whl (33 kB)\n",
            "Collecting opensearch-py<2.0.0,>=1.0.0\n",
            "  Downloading opensearch_py-1.1.0-py2.py3-none-any.whl (207 kB)\n",
            "\u001b[K     |████████████████████████████████| 207 kB 73.7 MB/s \n",
            "\u001b[?25hCollecting requests-aws4auth<2.0.0,>=1.1.1\n",
            "  Downloading requests_aws4auth-1.1.2-py2.py3-none-any.whl (24 kB)\n",
            "Collecting jsonpath-ng<2.0.0,>=1.5.3\n",
            "  Downloading jsonpath_ng-1.5.3-py3-none-any.whl (29 kB)\n",
            "Collecting backoff<2.0.0,>=1.11.1\n",
            "  Downloading backoff-1.11.1-py2.py3-none-any.whl (13 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.4 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<2.0.0,>=1.23.17->awswrangler) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 76.8 MB/s \n",
            "\u001b[?25hCollecting aenum<4.0.0,>=1.4.5\n",
            "  Downloading aenum-3.1.11-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 77.7 MB/s \n",
            "\u001b[?25hCollecting isodate<1.0.0,>=0.6.0\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 770 kB/s \n",
            "\u001b[?25hCollecting aiohttp<=3.8.1,>=3.8.0\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 51.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from gremlinpython<4.0.0,>=3.5.2->awswrangler) (1.5.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (21.4.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (4.1.1)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (2.0.12)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 73.6 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 73.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from isodate<1.0.0,>=0.6.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (1.15.0)\n",
            "Collecting ply\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from jsonpath-ng<2.0.0,>=1.5.3->awswrangler) (4.4.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl<3.1.0,>=3.0.0->awswrangler) (1.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from opensearch-py<2.0.0,>=1.0.0->awswrangler) (2021.10.8)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=1.2.0->awswrangler) (2022.1)\n",
            "Collecting scramp>=1.4.1\n",
            "  Downloading scramp-1.4.1-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: python-utils>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2<5.0.0,>=4.0.0->awswrangler) (3.1.0)\n",
            "Collecting beautifulsoup4<5.0.0,>=4.7.0\n",
            "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 78.0 MB/s \n",
            "\u001b[?25hCollecting lxml>=4.6.5\n",
            "  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 41.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<2.27.2,>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (21.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4<5.0.0,>=4.7.0->redshift-connector<2.1.0,>=2.0.889->awswrangler) (2.3.2.post1)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 69.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<2.27.2,>=2.23.0->redshift-connector<2.1.0,>=2.0.889->awswrangler) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<2.27.2,>=2.23.0->redshift-connector<2.1.0,>=2.0.889->awswrangler) (3.0.4)\n",
            "Collecting asn1crypto>=1.4.0\n",
            "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[K     |████████████████████████████████| 105 kB 74.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->redshift-connector<2.1.0,>=2.0.889->awswrangler) (3.0.8)\n",
            "Installing collected packages: urllib3, jmespath, multidict, frozenlist, botocore, yarl, s3transfer, asynctest, async-timeout, asn1crypto, aiosignal, scramp, ply, lxml, isodate, boto3, beautifulsoup4, aiohttp, aenum, requests-aws4auth, redshift-connector, pymysql, progressbar2, pg8000, opensearch-py, jsonpath-ng, gremlinpython, backoff, awswrangler\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Attempting uninstall: progressbar2\n",
            "    Found existing installation: progressbar2 3.38.0\n",
            "    Uninstalling progressbar2-3.38.0:\n",
            "      Successfully uninstalled progressbar2-3.38.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aenum-3.1.11 aiohttp-3.8.1 aiosignal-1.2.0 asn1crypto-1.5.1 async-timeout-4.0.2 asynctest-0.13.0 awswrangler-2.15.1 backoff-1.11.1 beautifulsoup4-4.11.1 boto3-1.21.44 botocore-1.24.44 frozenlist-1.3.0 gremlinpython-3.6.0 isodate-0.6.1 jmespath-1.0.0 jsonpath-ng-1.5.3 lxml-4.8.0 multidict-6.0.2 opensearch-py-1.1.0 pg8000-1.26.0 ply-3.11 progressbar2-4.0.0 pymysql-1.0.2 redshift-connector-2.0.906 requests-aws4auth-1.1.2 s3transfer-0.5.2 scramp-1.4.1 urllib3-1.25.11 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import awswrangler as wr\n",
        "import boto3\n",
        "\n",
        "\n",
        "# Boto3 session\n",
        "session = boto3.session.Session(aws_access_key_id='AKIA5MH7QKNBZZS7MENV', \n",
        "                                aws_secret_access_key='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')\n",
        "\n",
        "# Awswrangler pass forward all pd.read_csv() function args\n",
        "df = wr.s3.read_csv(path='s3://mis596adataset/compressedEnFr.csv',\n",
        "                    boto3_session=session)"
      ],
      "metadata": {
        "id": "mvhw8orIXfaU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n",
        "# df.columns.tolist()[2]\n",
        "df = df.drop('0', 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2QTLDGLoamS",
        "outputId": "3273329d-d2d3-4a74-de00-0abbf70349c5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "izk01e9Tpaf-",
        "outputId": "acae6a8c-a1e5-4d72-e69e-1fab1c85495e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      en  \\\n",
              "0                                               Site map   \n",
              "1                                               Feedback   \n",
              "2                                                Credits   \n",
              "3                                               Français   \n",
              "4                                        What is light ?   \n",
              "...                                                  ...   \n",
              "99994  • Karen Bron, Acting Director, Innovations, An...   \n",
              "99995            [ Previous | Table of Contents | Next ]   \n",
              "99996  ◦ Implementation of section 41 of the Official...   \n",
              "99997  To bring the communities together and make the...   \n",
              "99998  • Continue to organize and deliver a course fo...   \n",
              "\n",
              "                                                      fr  \n",
              "0                                           Plan du site  \n",
              "1                                            Rétroaction  \n",
              "2                                                Crédits  \n",
              "3                                                English  \n",
              "4                              Qu’est-ce que la lumière?  \n",
              "...                                                  ...  \n",
              "99994  ◦ Karen Bron, Directrice par intérim, Directio...  \n",
              "99995  [ Page précédente | Table des matières | Page ...  \n",
              "99996  ◦ Mise en œuvre de l'article 41 de la Loi sur ...  \n",
              "99997  Assurer un rapprochement des communautés et un...  \n",
              "99998  • Continuer d'organiser et de dispenser un cou...  \n",
              "\n",
              "[99999 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c32bf9cf-35a7-49aa-83d8-74e0b45850fc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Site map</td>\n",
              "      <td>Plan du site</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Feedback</td>\n",
              "      <td>Rétroaction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Credits</td>\n",
              "      <td>Crédits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Français</td>\n",
              "      <td>English</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is light ?</td>\n",
              "      <td>Qu’est-ce que la lumière?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99994</th>\n",
              "      <td>• Karen Bron, Acting Director, Innovations, An...</td>\n",
              "      <td>◦ Karen Bron, Directrice par intérim, Directio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>[ Previous | Table of Contents | Next ]</td>\n",
              "      <td>[ Page précédente | Table des matières | Page ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>◦ Implementation of section 41 of the Official...</td>\n",
              "      <td>◦ Mise en œuvre de l'article 41 de la Loi sur ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>To bring the communities together and make the...</td>\n",
              "      <td>Assurer un rapprochement des communautés et un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>• Continue to organize and deliver a course fo...</td>\n",
              "      <td>• Continuer d'organiser et de dispenser un cou...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99999 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c32bf9cf-35a7-49aa-83d8-74e0b45850fc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c32bf9cf-35a7-49aa-83d8-74e0b45850fc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c32bf9cf-35a7-49aa-83d8-74e0b45850fc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "\n",
        "data_path='/content/drive/MyDrive/compressedEnFr.csv'"
      ],
      "metadata": {
        "id": "veHMlnynF_Y0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(data_path, nrows=100000)"
      ],
      "metadata": {
        "id": "C4uTFnNZGOCS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "8cddb885-37d4-459d-e6dc-6fcb66fc7b38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-462837f40b2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/compressedEnFr.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.values.tolist()[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkV5ZsBDHwjO",
        "outputId": "e100daa7-1d9e-4222-9ed2-f5ae575f62c9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Feedback', 'Rétroaction']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# device type \"cuda\" or \"cpu\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "igY5PA-bGt42"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {} # word → index (word2index)\n",
        "        self.word2count = {} # index → word (index2word)\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2 # count SOS and EOS\n",
        "    \n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "            \n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    '''\n",
        "    For each character, there are two normal forms: \n",
        "    normal form C and normal form D. \n",
        "    Normal form D (NFD) is also known as canonical decomposition, and translates each character into its decomposed form. \n",
        "    Normal form C (NFC) first applies a canonical decomposition, then composes pre-combined characters again.\n",
        "    '''\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "metadata": {
        "id": "x4CoL12bIDQI"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 30 # max 10 words including ending punctuation\n",
        "hidden_size = 256"
      ],
      "metadata": {
        "id": "h3gUtyPGIyhC"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readLang(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "    # split into two lines\n",
        "    lines = df.values.tolist()\n",
        "    # select everyline into pairs and normalize\n",
        "    pairs = [\n",
        "        [normalizeString(str(s)) for s in l] for l in lines\n",
        "    ]\n",
        "\n",
        "    print(pairs[0])\n",
        "    \n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "# filtering to sentences that translate to the form “I am” or “He is” etc.\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[0].startswith(eng_prefixes)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "2u6GqiaXI0a4"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLang(lang1, lang2, reverse)\n",
        "    print(f\"Read sentence pairs: {len(pairs)}\")\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(f\"Trimmed to sentence pairs: {len(pairs)}\")\n",
        "    print(f\"COUNTING WORDS...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted Words...\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData(df.columns.tolist()[0], df.columns.tolist()[1])\n",
        "print(pairs)\n",
        "print(random.choice(pairs)) # random choice of pairs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmklnQu9JDNt",
        "outputId": "2fa80b0c-93b6-430d-d82b-4a4c70aab70c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "['site map', 'plan du site']\n",
            "Read sentence pairs: 99999\n",
            "Trimmed to sentence pairs: 163\n",
            "COUNTING WORDS...\n",
            "Counted Words...\n",
            "en 990\n",
            "fr 1102\n",
            "[['they are so good that years later dutch american astronomer gerard peter kuiper will include three of them in his photographic atlas of moon .', 'elles sont si bonnes que soixante ans plus tard en l astronome americano danois gerard peter kuiper en inclura trois dans son atlas photographique de la lune .'], ['they are .', 'il s agit des observatoires .'], ['he is currently writing his doctoral degree at the hebrew university in jerusalem still on the subject of english literature .', 'il effectue presentement son doctorat a l universite hebraique de jerusalem toujours en litterature anglaise .'], ['they are not however capable of distinguishing different colours and details and this causes the poor colour contrast between objects that we observe when the lighting is dim .', 'toutefois ils sont incapables de distinguer les couleurs et les details c est d ailleurs pour ces raisons que les objets nous paraissent moins colores dans la penombre .'], ['we are therefore always seeing cygni as it was more than years ago .', 'nous la voyons donc telle qu elle etait alors .'], ['we are actually looking at sirius as it looked . years ago .', 'nous regardons actuellement l etoile sirius dans son etat il y a annee .'], ['they are separated by immense voids that contain very few galaxies .', 'ils sont separes les uns des autres par d immenses vides dans lesquels on ne trouve que tres peu de galaxies .'], ['we re almost there aren t we ?', 'nous ne sommes plus tres loin en regardant son mari . . . n est ce pas ?'], ['they are attentive to quality nutritional value price and packaging .', 'ils sont attentifs a la qualite a la valeur nutritive au prix et a l emballage .'], ['they are clearly labelled on their front panel as to their medium gi or low gi ranking .', 'ils sont clairement etiquetes comme contenant un ig moyen ou un ig faible .'], ['they are all eager for a slice of the uae s us million fast food market .', 'ils sont tous impatients d obtenir leur part du marche de la restauration minute de millions de dollars americains aux emirats arabes unis .'], ['we are pleased to report that the emirates ranked as the least corrupt of the gcc countries and st overall .', 'nous sommes heureux de signaler que les emirats se sont classes comme l un des pays du ccg les moins corrompus au e rang .'], ['they are eager to obtain early registration of this product since their us counterparts already have the benefit of using mcp since last year .', 'ils attendent avec impatience que ce produit soit enregistre parce que leurs homologues americains peuvent deja l utiliser depuis l annee derniere .'], ['they are usually family run and staffed .', 'ce sont pour la plupart des entreprises familiales .'], ['they are interested in locating products that are innovative meaningful funky items with nice packaging a great taste with the concept of natural foods running through their line .', 'l entreprise cherche sans cesse des produits innovateurs pertinents et tendance des produits delicieux a l emballage attrayant dont la gamme contient des aliments naturels .'], ['they are open to many ranges with value added products and gourmet foods as a specialty .', 'gtk s interesse a de nombreuses gammes de produits a valeur ajoutee et aimerait faire des aliments gastronomiques sa specialite .'], ['we are committed to finding opportunities for canadian agri food businesses in the markets we serve .', 'nous nous employons a creer des possibilites pour le secteur agroalimentaire canadien dans les huit marches dont nous nous occupons .'], ['they are very strict in size and product specifications and very particular on value quality service and reliability .', 'elles sont tres exigeantes quant a la taille et aux specifications et sont egalement tres tatillonnes sur le rapport qualite prix le service et la fiabilite .'], ['they are classified as fresh dried dyed or bleached .', 'elles sont classees en diverses categories fleurs fraiches fleurs sechees fleurs teintes ou fleurs decolorees .'], ['i m offering the possibility of yellow rice and no blind children .', 'j offre la possibilite de consommer du riz dore et d eviter la cecite chez les enfants .'], ['they are also low in fat and contain more potassium than a banana and more iron than any other vegetable .', 'elle est egalement faible en gras et contient davantage de potassium qu une banane et plus de fer que n importe quel autre legume .'], ['they are made into chips flakes and french fries or starch for use by textile soap and paste companies .', 'la pomme de terre peut etre transformee en croustilles en flocons en frites ou en fecule destinee aux industries du textile du savon et des pates alimentaires .'], ['they are commonly used with the pan de sal or loaf bread .', 'on s en sert couramment avec le pain sale ou le pain en tranches .'], ['they are usually open hours a day days a week .', 'les depanneurs sont habituellement ouverts heures par jour jours par semaine .'], ['he is using the oyster bar house to introduce new products to the shanghai and east china market .', 'cette soiree a mis en vedette cinq produits de la mer canadiens au cours d une seance de degustation et d une presentation culinaire .'], ['they are very open minded to foreign food suppliers that can provide products which meet their requirements .', 'ils sont bien disposes a l utilisation de services provenant de fournisseurs d alimentation etrangers en mesure de fournir des produits pouvant satisfaire a leurs exigences .'], ['they are also responsible for creating technical standards policies and regulations .', 'elle est aussi responsable de la creation des normes techniques des politiques et des reglements en la matiere .'], ['they are also responsible for checking the quality weight and quantity .', 'il est aussi charge de verifier la qualite le poids et la quantite .'], ['they are central in formulating regulations governing genetically modified organisms gmo .', 'c est lui qui formule les reglements regissant les organismes genetiquement modifies ogm .'], ['they are able to compete on price market awareness and production costs .', 'elles peuvent soutenir la concurrence quant aux prix a la sensibilisation du marche et aux couts de production .'], ['they are both involved in a campaign to acquire smaller independent chains to maintain their dominant market shares .', 'cette hausse s explique surtout par la majoration des prix des fruits et des legumes du pain des mets a emporter et des aliments prets a consommer .'], ['they are not packaged or labeled with information about the products geographic origin and nutritional value .', 'ils ne sont ni emballes ni munis d une etiquette permettant de connaitre leur provenance ou leur valeur nutritionnelle .'], ['she is an internationally recognized country branding expert from the eric sprott school of business at carleton university in ottawa .', 'c est une experte mondialement reconnue de l image de marque nationale qui est professeure a la faculte de commerce eric sprott de l universite carleton a ottawa .'], ['we are interested in your feedback on this site or anything to do with the brand canada initiative .', 'nous aimerions savoir ce que vous pensez du present site ou de l initiative de promotion de l image de marque canada .'], ['we re known to be a trustworthy reliable and competent people .', 'les canadiens sont reconnus comme etant des personnes fiables serieuses et competentes .'], ['they re all available on this website with new material being added all the time .', 'ces renseignements sont offerts sur ce site web et nous ajoutons continuellement de nouveaux documents au site .'], ['we re including them as pdfs for download by registered users for convenience and reference .', 'vous pouvez les telecharger si vous etes un utilisateur inscrit ce sont des documents en format pdf mis a votre disposition pour vous aider et pour consultation .'], ['they are paving the way for an examination of new ways of supplying markets .', 'ces initiatives ouvrent la voie pour examiner de nouvelles facons d approvisionner les marches .'], ['we are moving with the trend says abraham in allusion to the current boom .', 'nous suivons la tendance de dire monsieur abraham faisant allusion a la conjoncture ascendante actuelle .'], ['they are well funded pay attention to their nutrition and prefer smaller package sizes .', 'ils sont bien nantis font attention a leur alimentation et preferent des emballages de plus petite taille .'], ['we are convinced that taking this step will assist in promoting the conservation of stocks said peter dill the managing director .', 'nous sommes convaincus qu en prenant cette mesure nous concourons a favoriser la conservation des stocks de declarer peter dill directeur general .'], ['they are also very optimistic for the development of milk puddings wet and instant .', 'milupa anticipe un bilan favorable pour les prochains mois .'], ['they are followed by superstores with . and supermarkets with . . .', 'viennent ensuite les hypermarches avec une part de et les supermarches dont la part se situe a .'], ['they are developing new natural colours and aromas .', 'ils concoivent des produits novateurs du point de vue de leurs couleurs et de leurs parfums naturels .'], ['he is convinced that the presently strong demand for organic foods is anything but a flash in the pan .', 'il est convaincu que la forte demande actuelle de produits biologiques n a rien d un feu de paille .'], ['you are interested ?', 'etes vous interesse ?'], ['they are hardy animals that graze in a variety of tame pastures wild pastures and wet meadows .', 'c est un animal robuste qui peut se nourrir dans differents types de prairies artificielles naturelles semees et humides .'], ['they are willing to pay extra for convenience and appreciate attractive packaging .', 'ils sont prets a payer plus cher pour gagner du temps dans la cuisine et apprecient les emballages attrayants .'], ['they are available at the following addresses ', 'on peut les consulter sur internet aux adresses suivantes '], ['they are also concerned about environmentally sound land management and farming practices .', 'il exige egalement des pratiques acceptables en matiere de gestion des terres et d agriculture .'], ['they are aware of food additives read labels and demand a lot of information about the products they consume .', 'ils connaissent les additifs alimentaires lisent les etiquettes et s informent attentivement sur les produits qu ils consomment .'], ['they are issued by the registrar general of the secretariat of trade in spain and are valid only for six months .', 'elles sont delivrees par le registraire general du secretariat du commerce d espagne et sont valides pendant six mois seulement .'], ['they are not malls yet but could be considered mini malls .', 'il ne s agit pas de centres commerciaux a proprement parler mais ils pourraient etre consideres comme des minicentres commerciaux .'], ['they are interested in a whole range of products including health and wellness and high end food products .', 'ils s interessent a un large eventail de produits dont des produits de sante et de bien etre et des aliments de qualite superieure .'], ['they are an excellent source of complex carbohydrates and are high in fibre and in protein .', 'les lentilles sont une excellente source de glucides complexes et ont une forte teneur en fibres alimentaires et en proteines .'], ['they are also subject to a value added tax .', 'elles font aussi l objet d une taxe de valeur ajoutee de .'], ['they are also the primary industrial centres in spain .', 'ils constituent egalement les principaux centres industriels de l espagne .'], ['they are a promising consumer market for food particularly ready made and convenience products .', 'en ils representaient des menages danois .'], ['they are often challenged to prove non gm compliance for ingredients by providing a complete audit trail for traceability .', 'seule une entreprise audacieuse pour ne pas dire stupide oserait les affronter directement sur une question qui a donne lieu a tant de declarations assurees et non ambigues .'], ['we are phasing out the use of another .', 'nous sommes actuellement en train d en eliminer progressivement de plus .'], ['we are keeping this matter under regular review in the light of customer demand for items such as non gm milk .', 'cela signifie qu on ne peut pas passer a des produits entierement non gm que ce n est pas faisable du moins dans un futur proche .'], ['we are also grateful to many officials of the european commission for their expert advice and review of relevant sections .', 'nous sommes egalement reconnaissants aux nombreux representants de la commission europeenne qui nous ont fait beneficier de leur expertise et qui ont revise les sections pertinentes .'], ['we are cfia eu fda and haccp approved .', 'nos operations sont sanctionnees par l acia l ue la fda et l haccp .'], ['we are continually reviewing new opportunities to expand our base through new products and new markets .', 'nous examinons continuellement les nouvelles possibilites d elargir notre base grace a de nouveaux produits et a de nouveaux marches .'], ['we are committed to having our wild salmon seen as a first choice natural and canadian .', 'son but est de faire connaitre le saumon sauvage de la colombie britannique comme un produit exceptionnel naturel et canadien .'], ['they are available to establish contacts between european companies and canadian seafood exporters .', 'ils etablissent des liens entre les entreprises europeennes et les exportateurs canadiens de fruits de mer .'], ['they are going back home with the memory of a beautiful country and a fertile land for the china canada scientific cooperation .', 'ils reviennent au pays avec le souvenir d un magnifique pays et d un terrain fertile pour la collaboration scientifique chine canada .'], ['he is m .a . economics and ll .m . constitution and administrative law bombay university .', 'il possede une maitrise en economie et une maitrise en droit specialisation en droit constitutionnel et en droit administratif de l universite de bombay .'], ['we re delighted with the results and have booked a significantly larger stand for ! mr georg weber mkn germany', 'nous sommes enchantes des resultats et nous avons reserve un stand beaucoup plus grand pour ! georg weber mkn allemagne'], ['we are looking specifically for italian manufactured equipment .', 'nous recherchons specifiquement de l equipement fabrique en italie .'], ['we are the exclusive distributors for fiesta brand gas bbq s in asia as well as various potential other markets .', 'elle est la seule a distribuer des barbecues au gaz de marque fiesta en asie et espere d ailleurs agrandir son marche .'], ['we are the only group in the industry to routinely use high technology laboratory instruments such as an electronic refractometer and an atomic absorption spectrophotometer .', 'les outils de laboratoire de haute technologie utilises notamment le refractometre electronique et le spectrophotometre d absorption atomique sont egalement uniques dans l industrie .'], ['they are also an excellent resource for first hand information on a culture .', 'ces sites sont d excellentes ressources pour ceux qui veulent se renseigner de premiere main sur une culture .'], ['you are on your way to becoming export ready but further preparation may be required to avoid possible hazards and delays ahead .', 'vous etes en voie d acquerir la capacite d exporter mais d autres preparatifs pourraient etre necessaires si vous voulez eviter d eventuels dangers et retards .'], ['they are also very loyal .', 'ils sont en outre tres fortement caracterises par leur loyaute .'], ['he is twice as likely to be illiterate and his life expectancy is ten years shorter .', 'la probabilite qu il soit illettre est deux fois plus elevee et son esperance de vie est plus courte de dix ans .'], ['they are looking for contracts that secure stable prices .', 'ils cherchent a conclure des contrats qui leur garantiraient des prix stables .'], ['they are generally free to set prices and determine their own promotion policies .', 'ils sont en general libres de fixer les prix et d etablir leurs propres politiques de promotion .'], ['they are the traditional retail outlet for neighbourhoods particularly in smaller and remote towns .', 'ils constituent les points de vente de quartier traditionnels surtout dans les petites villes et les villes isolees .'], ['we are producers and our products come from the provinces of alberta and ontario .', 'nous sommes producteurs et nos produits viennent des provinces canadiennes de l alberta et de l ontario .'], ['we are proud that mccain products are in the best restaurant chains and in millions of homes worldwide .', 'nous sommes fiers que les produits mccain sont consommes dans les meilleures chaines de restaurants et dans des millions de foyers a l echelle mondiale .'], ['we are exclusive suppliers of sterling silver and certified angus beef .', 'nous fournissons exclusivement de la viande de b uf de marque sterling silver et certified angus .'], ['they are frequently located out of town or constitute the anchor store in a shopping centre .', 'ils sont souvent situes en banlieue ou encore ils font office de magasin pilier dans un centre commercial .'], ['they are arguing that the ban on genetically modified foods is a serious mistake for which poland will pay for in the future .', 'ils soutiennent que d interdire les aliments genetiquement modifies est une grave erreur qui s averera couteuse pour la pologne .'], ['you are encouraged to present your new and current product lines .', 'surveillez l invitation qui vous parviendra sous peu .'], ['he is active in nafta and wto dispute settlement both as counsel and as an arbitrator .', 'il participe au reglement des differends relativement a l alena et a l omc tant comme conseiller qu arbitre .'], ['we are confident that we have reliable tangible facts on production and sales volume number of producers desires and capabilities .', 'nous sommes confiants d avoir rassemble des donnees fiables et reelles sur les volumes de production et de vente le nombre de producteurs les attentes et les capacites .'], ['they are the organic crop improvement association ocia nb chapter and the maritime certified organic growers ltd .', 'ce sont l organic crop improvement association ocia section du n . b . et la maritime certified organic growers ltd .'], ['we are currently awaiting their report on their findings .', 'nous attendons actuellement les conclusions du rapport de la commission .'], ['he is authorized to issue cifsc halal certificates for food products meant for distribution by misom .', 'il est habilite a delivrer des certificats halal au nom du cifsc pour les produits alimentaires que distribue misom .'], ['they are seeking regular importers and or processors in europe for their high quality products .', 'la societe recherche des importateurs et transformateurs reguliers en europe pour ses produits de premier choix .'], ['they are very interested in expanding sales into europe and look forward to requests for their canadian seafood items .', 'la societe est tres desireuse de pouvoir etendre ses ventes en europe et recherche de la demande pour ses fruits de mer canadiens .'], ['they are seeking buyers for manila clams and gooseneck barnacles in the european market .', 'elle recherche des acheteurs de palourdes japonaises et de pouces pieds sur le marche europeen .'], ['they are seeking regular importers and or processors in europe for their high quality products .', 'la societe recherche des importateurs et ou transformateurs reguliers en europe pour ses produits de premier choix .'], ['they are particularly rich in protein and minerals while being low in fat sodium and cholesterol .', 'elle est particulierement riche en proteines et en mineraux tout en etant faible en gras en sodium et en cholesterol .'], ['they are fished from the sacramento river in california to the mackenzie river in canada s yukon territory .', 'il est peche depuis la riviere sacramento en californie jusqu au fleuve mackenzie dans le territoire canadien du yukon .'], ['they are fed a special diet until they reach market size between eight and ten pounds .', 'ils sont nourris de farine jusqu a ce qu ils atteignent la taille marchande soit entre et livres .'], ['they are a very deepwater species living near sea bottom in the subarctic to the antarctic regions .', 'c est une espece qui vit en eau tres profonde pres du fond de l ocean de l antarctique aux regions subarctiques .'], ['they are harvested year round by almost any harvesting method either in directed fisheries or as bycatch .', 'on le capture toute l annee a la peche selective ou en prise accessoire par des methodes tres diverses .'], ['they are the least supportive of frozen desserts or toppings baked goods and ice cream .', 'ce sont eux qui consomment le moins de desserts ou de garnitures glacees de patisseries et de cremes glacees .'], ['they are willing to spend more for better quality products and are loyal to businesses and brands able to provide that .', 'les hispaniques n hesitent pas a payer plus cher des produits de meilleure qualite et sont fideles aux commerces et aux marques qui leur fournissent ces produits .'], ['they are found on nearly every street in manhattan and are scattered throughout the outer boroughs and suburbs as well .', 'ils se trouvent pratiquement sur toutes les rues de manhattan et dans tous les bourgs exterieurs et les banlieues .'], ['they are the primary source of supply for all of the natural food retailers and always have the attention of their customers .', 'ces distributeurs representent les principales sources d approvisionnement pour les detaillants en aliments naturels et ont toujours l attention de leurs clients .'], ['they are designed to clarify patentability as it applies to gene based inventions .', 'elles ont pour but de clarifier la brevetabilite relativement aux inventions reposant sur les genes .'], ['they re desperate . the most high profile example of this trend is celera genomics .', 'elles sont desesperees . l exemple le plus en vue de cette tendance est l entreprise celera genomics .'], ['they are now asking for more equity and solid near future prospects of revenues .', 'ils demandent maintenant plus de fonds propres et des perspectives de revenus solides a court terme .'], ['they are particularly appealing to experienced cruisers and seniors as well as the corporate incentive and conference meeting markets .', 'elles attirent principalement les personnes qui ont deja fait des croisieres et les personnes agees ainsi que les gens d affaires .'], ['they are familiar with and accustomed to north american food products .', 'ils connaissent donc les produits alimentaires nord americains .'], ['they are more likely to be familiar with canadian products and often load product while in port .', 'il y a plus de chance que ces compagnies connaissent les produits canadiens et en achetent pendant leurs escales .'], ['we are willing to work with the fda to increase the level of canadian industry compliance through outreach and education activities .', 'nous sommes disposes a collaborer avec la fda pour augmenter le niveau de conformite de l industrie canadienne grace a des activites d information et de sensibilisation .'], ['we are submitting a sample of invoices for reference .', 'vous trouverez ci joint des exemples de factures .'], ['i am suspect of their beef .', 'je me mefie de ce boeuf .'], ['we are currently buying it through a broker .', 'a l heure actuelle nous effectuons nos achats par l entremise d un courtier .'], ['i am looking for value .', 'j accorde avant tout de l importance a la valeur .'], ['we are all the same but different . ', 'nous sommes tous pareils mais differents .'], ['i am sick .', 'je suis malade .'], ['she is looking for the pox .', 'elle cherche la variole .'], ['she is checking you for syphilis . ', 'elle regarde pour voir si tu as la syphilis .'], ['they are crawling with weevils !', 'ils sont pleins de charancons .'], ['you are on defaulters tonight and you will wash all the dishes by yourself .', 'tu es en defaillance ce soir et tu laveras toute la vaisselle tout seul .'], ['they are usually a picture or symbol of some relevance to the person .', 'ils sont habituellement un dessin ou un symbole ayant une certaine pertinence pour la personne .'], ['he s only a boy .', 'c est seulement un garcon .'], ['you are growing too fast .', 'tu grandis trop vite .'], ['they re eating all the biscuits ! ', 'ils mangent tous les biscuits .'], ['they are usually three feet wide and six feet long .', 'les pantalons des officiers etaient plus formels et serres .'], ['he is accepted as the first person of european background to cross north america north of mexico .', 'il est accepte comme la premiere personne de descendance europeenne a traverser l amerique du nord au nord du mexique .'], ['they are described as a keystone species because they have a major impact on the ecosystem .', 'on les decrit comme une espece cle parce qu elles ont un impact majeur sur l ecosysteme .'], ['they are filled with inlets peninsulas and numerous small islands .', 'cartographier seulement une petite etendue d eau necessite du temps et de la patience .'], ['they are designed to catch and transmit the flow of the wind so that the energy of the moving air can propel the ship through the water .', 'elles sont concues pour capter les courants d air pour que l energie de l air en mouvement propulse le navire dans l eau .'], ['i am hoping to locate information about my ancestors .', 'j aimerais trouver des renseignements sur mes ancetres ou puis je trouver de l aide ? .'], ['we re going cable ! natural sciences and engineering research council of canada ', 'bientot sur le cable ! conseil de recherche en sciences naturelles et en genie du canada '], ['they are ready to deploy finance canada ', 'ils sont prets a partir finances canada '], ['we re years old ! national defence ', 'nous avons ans ! defense nationale '], ['i m not getting any younger get money now to help you start saving for your child s education or training after high school .', 'je ne rajeunis pas obtenez de l argent maintenant pour vous aider a epargner pour la formation et les etudes postsecondaires de votre enfant .'], ['we are grateful to all those who took the time to respond to our consultations .', 'nous savons gre a tous d avoir pris le temps de repondre a nos consultations .'], ['we are recommending the establishment of a legal clinic to assist with legal representation .', 'nous recommandons qu une clinique juridique soit mise sur pied pour les y aider .'], ['we are aware that making adr part of the tribunal process might appear to make the adr process more focused on the legal issues .', 'nous savons que l integrer au processus peut donner l impression qu il est davantage axe sur les questions juridiques .'], ['we are concerned that the bulk of resources could be diverted to the administering body .', 'nous craindrions que le gros des ressources soit detourne vers l agence administrative .'], ['we are recommending powers that would make it even more informed about trends in equality .', 'nous recommandons de lui attribuer des pouvoirs qui lui permettraient d etre encore mieux eclairee sur les tendances dans ce domaine .'], ['we are of the view that the protection provided by parliament to pardoned criminal offenders should be extended to individuals convicted or charged with a criminal offence .', 'nous sommes d avis que la protection que le parlement accorde aux personnes condamnees et graciees devrait etre etendue aux personnes condamnees et accusees d un acte criminel .'], ['we are concerned that a number of convicted canadians do not know about or have access to the pardon process .', 'nous sommes preoccupes du fait que nombre de personnes condamnees ne sont pas au courant de la procedure de rehabilitation ou n y ont pas acces .'], ['we are concerned about the somewhat arbitrary distinction drawn in the act between pardoned and unpardoned offenders .', 'nous nous preoccupons de la distinction quelque peu arbitraire que fait la loi entre une personne graciee et une qui ne l est pas .'], ['they are difficult to prove because they do not challenge the discrimination directly .', 'ils sont difficiles a prouver parce que l effet de discrimination est indirect .'], ['we are afraid that this will not be provided in the canadian act .', 'nous avons peur aussi que la loi canadienne sur les droits de la personne n en tienne pas compte .'], ['we are afraid of being excluded .', 'nous avons peur d etre exclues .'], ['we are of the view that there is ample reason to extend the prohibition in section to internet technologies and other technologies that may evolve .', 'nous croyons qu il y a de bonnes raisons d etendre l interdiction prescrite par l article a l internet et aux technologies futures .'], ['we are of the view that to remove any doubt a similar provision should be added to the act .', 'nous croyons qu une disposition semblable devrait etre ajoutee a la loi pour dissiper tout doute a ce sujet .'], ['we are concerned that greater clarity is needed in the scope of the orders the tribunal can make .', 'il nous importe que la portee des ordonnances du tribunal soit precisee .'], ['we are concerned that the eea does not allow for the participation of community groups in the process .', 'nous sommes egalement preoccupes du fait que la lee ne permet pas la participation des groupes communautaires au processus .'], ['we are of the view that a number of tools have to be given to the commission to achieve the goals of the act ', 'nous croyons qu un certain nombre d outils doivent etre mis a la disposition de la commission pour realiser les objectifs de la loi '], ['we are concerned about the effect of imposing a joint workplace human rights committee structure on employers .', 'nous nous inquietons de l effet d imposer aux employeurs une structure de comite conjoint des droits de la personne en milieu de travail .'], ['they are very effective in addressing systemic discrimination as the development of the rules provides a process that involves all interested parties .', 'elles sont tres efficaces contre la discrimination systemique puisque leur elaboration engage toutes les parties interessees .'], ['they are based on the considerable expertise that the commission has or can bring to bear on an issue .', 'elles sont fondees sur l expertise considerable que la commission possede ou peut mettre a profit sur une question .'], ['they are used in the human rights context in various jurisdictions for example in australia the united kingdom and the united states .', 'on le fait dans plusieurs pays notamment en australie au royaume uni et aux etats unis dans le contexte des droits de la personne .'], ['we are very much in agreement with this statement .', 'nous sommes tout a fait d accord avec cette affirmation .'], ['they are under surveillance but not charged .', 'ces gens sont sous surveillance mais ne sont pas accuses .'], ['they are further responsible for ensuring collaboration in this area both within the department and where required between federal departments and agencies and other levels of government .', 'ils sont egalement responsables de la planification de la mise en uvre et de l evaluation des initiatives de participation du public .'], ['you are invited to forward your comments by february to the following address ', 'vous etes invites a transmettre vos observations au plus tard le fevrier a l adresse suivante '], ['i am therefore of the view that the better course to follow is to continue the system of two separate commissioners .', 'je suis donc d avis que la meilleure solution est de conserver le systeme a deux commissaires distincts .'], ['i am supported in this conclusion by the vast majority of the persons consulted during the course of conducting this review .', 'ma conclusion sur ce point est etayee par la vaste majorite des personnes consultees durant la periode du present examen .'], ['they are presented in relationship to the department s program activity architecture paa .', 'elles sont presentees en fonction de l architecture d activite de programme aap du ministere .'], ['they are presented in relationship to the department s program activity architecture paa .', 'elles sont presentees en fonction de l architecture d activite de programme aap du ministere .'], ['we are putting mechanisms in place to make our programs better known to the community organizations .', 'nous mettons en place des mecanismes pour faire connaitre nos programmes aupres des organismes communautaires .']]\n",
            "['you are encouraged to present your new and current product lines .', 'surveillez l invitation qui vous parviendra sous peu .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedding = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedding\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    \"\"\"docstring for DecoderRNN\"\"\"\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "3sJSJ0CnJN0o"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "HPKJ0AliKIay"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "# Preparing Training Data\n",
        "# To train, for each pair we will need an input tensor (indexes of the words in the input sentence) and target tensor (indexes of the words in the target sentence). \n",
        "# While creating these vectors we will append the EOS token to both sequences.\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "VrYtGAo6KMzx"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden\n",
        "        )\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden\n",
        "            )\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di] # Teacher forcing\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden\n",
        "            )\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach() # detach from history as input\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    return loss.item() / target_length"
      ],
      "metadata": {
        "id": "dW9g1ng2KaXH"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(s))"
      ],
      "metadata": {
        "id": "FCMHxVjtKrjm"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def showplot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7KYpLL8iKuAK"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0 # Reset every print_every\n",
        "    plot_loss_total = 0 # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    training_pairs = [tensorFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(\n",
        "            input_tensor, target_tensor, \n",
        "            encoder, decoder, \n",
        "            encoder_optimizer, decoder_optimizer, \n",
        "            criterion\n",
        "        )\n",
        "\n",
        "        print_loss_total += loss  \n",
        "        plot_loss_total += loss  \n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "    showplot(plot_losses)"
      ],
      "metadata": {
        "id": "uvMCbTpcKv06"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words\n",
        "\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "trainIters(encoder1, decoder1, 75000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnisSzM8LAi0",
        "outputId": "4ee33ae1-4603-4dd1-d553-376da16d5af8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1m 59s (- 1m 59s) (5000 6%) 2.7357\n",
            "4m 0s (- 4m 0s) (10000 13%) 0.0721\n",
            "6m 2s (- 6m 2s) (15000 20%) 0.0198\n",
            "8m 5s (- 8m 5s) (20000 26%) 0.0147\n",
            "10m 7s (- 10m 7s) (25000 33%) 0.0112\n",
            "12m 9s (- 12m 9s) (30000 40%) 0.0116\n",
            "14m 10s (- 14m 10s) (35000 46%) 0.0091\n",
            "16m 12s (- 16m 12s) (40000 53%) 0.0085\n",
            "18m 12s (- 18m 12s) (45000 60%) 0.0083\n",
            "20m 14s (- 20m 14s) (50000 66%) 0.0063\n",
            "22m 15s (- 22m 15s) (55000 73%) 0.0086\n",
            "24m 15s (- 24m 15s) (60000 80%) 0.0087\n",
            "26m 16s (- 26m 16s) (65000 86%) 0.0081\n",
            "28m 17s (- 28m 17s) (70000 93%) 0.0063\n",
            "30m 19s (- 30m 19s) (75000 100%) 0.0094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')\n",
        "evaluateRandomly(encoder1, decoder1)"
      ],
      "metadata": {
        "id": "wlKJN_TiLOH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95c3ba84-77eb-45ba-ee38-95d49f6069d9"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> we are interested in your feedback on this site or anything to do with the brand canada initiative .\n",
            "= nous aimerions savoir ce que vous pensez du present site ou de l initiative de promotion de l image de marque canada .\n",
            "< nous aimerions savoir ce que vous pensez du present site ou de l initiative de promotion de l image de marque canada . <EOS>\n",
            "\n",
            "> they are the primary source of supply for all of the natural food retailers and always have the attention of their customers .\n",
            "= ces distributeurs representent les principales sources d approvisionnement pour les detaillants en aliments naturels et ont toujours l attention de leurs clients .\n",
            "< ces distributeurs representent les principales sources d approvisionnement pour les detaillants en aliments naturels et ont toujours l attention de leurs clients . <EOS>\n",
            "\n",
            "> they re all available on this website with new material being added all the time .\n",
            "= ces renseignements sont offerts sur ce site web et nous ajoutons continuellement de nouveaux documents au site .\n",
            "< ces renseignements sont offerts sur ce site web et nous ajoutons continuellement de nouveaux documents au site . <EOS>\n",
            "\n",
            "> they are an excellent source of complex carbohydrates and are high in fibre and in protein .\n",
            "= les lentilles sont une excellente source de glucides complexes et ont une forte teneur en fibres alimentaires et en proteines .\n",
            "< les lentilles sont une excellente source de glucides complexes et ont une forte teneur en fibres alimentaires et en proteines . <EOS>\n",
            "\n",
            "> they are issued by the registrar general of the secretariat of trade in spain and are valid only for six months .\n",
            "= elles sont delivrees par le registraire general du secretariat du commerce d espagne et sont valides pendant six mois seulement .\n",
            "< elles sont delivrees par le registraire general du secretariat du commerce d espagne et sont valides pendant six mois seulement . <EOS>\n",
            "\n",
            "> we re almost there aren t we ?\n",
            "= nous ne sommes plus tres loin en regardant son mari . . . n est ce pas ?\n",
            "< nous ne sommes plus tres loin en regardant son mari . . . n est ce pas ? <EOS>\n",
            "\n",
            "> we are of the view that there is ample reason to extend the prohibition in section to internet technologies and other technologies that may evolve .\n",
            "= nous croyons qu il y a de bonnes raisons d etendre l interdiction prescrite par l article a l internet et aux technologies futures .\n",
            "< nous croyons qu il y a de bonnes raisons d etendre l interdiction prescrite par l article a l internet et aux technologies futures . <EOS>\n",
            "\n",
            "> they are also very optimistic for the development of milk puddings wet and instant .\n",
            "= milupa anticipe un bilan favorable pour les prochains mois .\n",
            "< milupa anticipe un bilan favorable pour les prochains mois . <EOS>\n",
            "\n",
            "> she is an internationally recognized country branding expert from the eric sprott school of business at carleton university in ottawa .\n",
            "= c est une experte mondialement reconnue de l image de marque nationale qui est professeure a la faculte de commerce eric sprott de l universite carleton a ottawa .\n",
            "< c est une experte mondialement reconnue de l image de marque nationale qui est professeure a la faculte de commerce eric sprott de l universite carleton a ottawa . <EOS>\n",
            "\n",
            "> they are .\n",
            "= il s agit des observatoires .\n",
            "< il s agit des observatoires . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "def translateText(input_text):\n",
        "    output_words = evaluate(\n",
        "        encoder1, decoder1, normalizeString(input_text)\n",
        "    )\n",
        "    output_sentence = ' '.join(output_words)\n",
        "    return f\"Output Sentence: {output_sentence}\"\n",
        "\n",
        "translateText(input_text=input(\"Type sentence: \"))"
      ],
      "metadata": {
        "id": "V85AplR1LWNT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "631247e9-bdf0-4bb4-889a-7689061c28df"
      },
      "execution_count": 63,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Type sentence: they are complex carbohydrates\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Output Sentence: ils sont prets a partir finances canada  <EOS>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GSGyhdB5YQ2c"
      },
      "execution_count": 59,
      "outputs": []
    }
  ]
}